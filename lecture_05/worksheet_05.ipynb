{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 05\n",
    "\n",
    "Name:  Zihan Li\n",
    "\n",
    "UID: U83682995\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Cost Functions\n",
    "- Kmeans\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
    "\n",
    "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
    "\n",
    "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
    "\n",
    "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
    "\n",
    "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means\n",
    "\n",
    "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
    "\n",
    "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
    "\n",
    "Given the initial centroids:\n",
    "\n",
    "`[0, 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1\n",
    "Dataset: [0, 0.5, 1.5, 2, 6, 6.5, 7]\n",
    "Initial centroids: [0, 2]\n",
    "\n",
    "Step 2\n",
    "For centroid 0, the closest points are [0, 0.5].\n",
    "For centroid 2, the closest points are [1.5, 2, 6, 6.5, 7].\n",
    "\\\n",
    "Step 3\n",
    "New centroid for cluster 1 (previously centered at 0): mean([0, 0.5]) = 0.25\n",
    "New centroid for cluster 2 (previously centered at 2): mean([1.5, 2, 6, 6.5, 7]) = 4.6\n",
    "\n",
    "Step 4\n",
    "With the new centroids, we repeat the assignment step.\n",
    "\n",
    "For centroid 0.25, the closest points are now [0, 0.5, 1.5].\n",
    "For centroid 4.6, the closest points are [2, 6, 6.5, 7].\n",
    "\n",
    "Step 5\n",
    "Update the centroids of each cluster again.\n",
    "\n",
    "New centroid for cluster 1: mean([0, 0.5, 1.5]) = 0.67 (approximately)\n",
    "New centroid for cluster 2: mean([2, 6, 6.5, 7]) = 5.38 (approximately)\n",
    "We will repeat steps 4 and 5 (Assignment and Update) until the centroids do not change significantly, indicating that the algorithm has converged.\n",
    "\n",
    "After recalculating, the new centroids are approximately:\n",
    "New centroid for cluster 1: 0.67\n",
    "New centroid for cluster 2: 5.38\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe in plain english what the cost function for k means is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The cost function for k-means measures how spread out the clusters are. It calculates the distance from each point to its cluster's center, squares these distances, and then adds them all up. The goal is to make this total as small as possible, meaning the clusters are tight and compact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-means algorithm can yield different solutions for the same number of clusters on a given dataset due to random initialization of centroids, the tendency to find local minima rather than the global minimum, varying convergence criteria, and sensitivity to data distribution and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Does Lloyd's Algorithm always converge? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Lloyd's Algorithm always converges because it continually reduces or maintains a cost measure, which has a lower limit, leading to a stable configuration where the cost can't be further reduced, although it may not be the optimal solution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Follow along in class the implementation of Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.0-1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "     --------------------------------------- 10.6/10.6 MB 59.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\73907\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.26.3)\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.12.0-cp311-cp311-win_amd64.whl (46.2 MB)\n",
      "     --------------------------------------- 46.2/46.2 MB 72.5 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "     ---------------------------------------- 302.2/302.2 kB ? eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.4.0 scipy-1.12.0 threadpoolctl-3.2.0\n",
      "[[-3.25873474  1.80410328]\n",
      " [-0.50173528  0.56587087]\n",
      " [ 1.83555022 -4.10276176]\n",
      " [ 1.88512895  1.53939516]]\n",
      "[[-3.14555626  1.85455619]\n",
      " [-0.29808003  0.19297643]\n",
      " [ 1.84180743 -4.03258775]\n",
      " [ 1.90104571  1.8261627 ]]\n",
      "[[-3.10208548  1.85147285]\n",
      " [-0.13209903  0.06838121]\n",
      " [ 1.84126343 -4.06791444]\n",
      " [ 1.90165131  1.93255625]]\n",
      "[[-3.07703402  1.85266958]\n",
      " [-0.03760357  0.01175879]\n",
      " [ 1.84585117 -4.10098602]\n",
      " [ 1.904406    1.98450725]]\n",
      "[[-3.07703402  1.85266958]\n",
      " [-0.01886062  0.02039989]\n",
      " [ 1.84585117 -4.10098602]\n",
      " [ 1.91248297  2.00204407]]\n",
      "[[-3.07703402  1.85266958]\n",
      " [-0.01886062  0.02039989]\n",
      " [ 1.84585117 -4.10098602]\n",
      " [ 1.91248297  2.00204407]]\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "centers = [[0, 0], [2, 2], [-3, 2], [2, -4]]\n",
    "X, _ = datasets.make_blobs(n_samples=300, centers=centers, cluster_std=1, random_state=0)\n",
    "\n",
    "class KMeans():\n",
    "\n",
    "    def __init__(self, data, k):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.assignment = [-1 for _ in range(len(data))]\n",
    "        self.snaps = []\n",
    "    \n",
    "    def snap(self, centers):\n",
    "        TEMPFILE = \"temp.png\"\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=self.assignment)\n",
    "        ax.scatter(centers[:,0], centers[:, 1], c='r')\n",
    "        fig.savefig(TEMPFILE)\n",
    "        plt.close()\n",
    "        self.snaps.append(im.fromarray(np.asarray(im.open(TEMPFILE))))\n",
    "        \n",
    "    def is_unassigned(self, i):\n",
    "        return self.assignment[i] == -1\n",
    "    \n",
    "    def unassign_all(self):\n",
    "        self.assignment = [-1 for _ in range(len(self.data))]\n",
    "        \n",
    "    def initialize(self):\n",
    "        return self.data[np.random.choice(range(len(self.data)), size=self.k, replace=False)]\n",
    "    \n",
    "    def are_centers_diff(self, c1, c2):\n",
    "        for i in range(len(c1)):\n",
    "            if c1[i] not in c2:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def assign(self, centers):\n",
    "        for i in range(len(self.data)):\n",
    "            self.assignment[i] = 0\n",
    "            temp_assign = 0\n",
    "            temp_dist = self.dist(self.data[i], centers[0])\n",
    "            for j in range(1, len(centers)):\n",
    "                new_dist = self.dist(self.data[i], centers[j])\n",
    "                if temp_dist > new_dist:\n",
    "                    self.assignment[i] = j\n",
    "                    temp_dist = new_dist\n",
    "    \n",
    "    def calculate_new_centers(self):\n",
    "        centers = []\n",
    "        for j in range(self.k):\n",
    "            cluster_j = self.data[\n",
    "                np.array([i for i in range(len(self.data)) if self.assignment[i] == j])\n",
    "            ]\n",
    "            centers.append(np.mean(cluster_j,axis=0))\n",
    "        \n",
    "        return np.array(centers)\n",
    "\n",
    "    def dist(self, x, y):\n",
    "        return sum((x - y) ** 2) ** (1/2)\n",
    "\n",
    "    def lloyds(self):\n",
    "        centers = self.initialize()\n",
    "        self.assign(centers)\n",
    "        self.snap(centers)\n",
    "        new_centers = self.calculate_new_centers()\n",
    "        while self.are_centers_diff(centers, new_centers):\n",
    "            centers = new_centers\n",
    "            self.snap(centers)\n",
    "            self.unassign_all()\n",
    "            self.assign(centers)\n",
    "            new_centers = self.calculate_new_centers()\n",
    "            print (new_centers)\n",
    "        return\n",
    "            \n",
    "kmeans = KMeans(X, 4)\n",
    "kmeans.lloyds()\n",
    "images = kmeans.snaps\n",
    "\n",
    "images[0].save(\n",
    "    'kmeans.gif',\n",
    "    optimize=False,\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    loop=0,\n",
    "    duration=500\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
